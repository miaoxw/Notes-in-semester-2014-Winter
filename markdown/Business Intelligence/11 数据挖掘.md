#11 Data Mining
数据库及数据仓库中存储有大量数据。充分开发、利用这些数据资源是一项重要工作。
#####数据资源的利用方式
* 数据资源的查询服务  
可以针对原子层，也可以针对聚集数据进行查询
* 数据资源的演绎    
应当提供定制化的查询方式  
查询结果是稳定的
任何可能有助于分析应用的工具都可能会被使用  
典型应用：专家系统  
OLAP并非简单的输入/输出过程，存在相关的交互，由人来判断下一步要做什么
* 数据资源的归纳  
***数据挖掘***
#####三种利用方式之间的区别
* 使用数据挖掘技术可以发现用户未知的信息
* 使用数据挖掘技术可以寻找到具有普遍意义的知识，并将其应用到其它同类应用中，以帮助用户进行决策

前两种利用方式都是一种确定性的计算，而数据挖掘以接近人的方式做推断
##一、数据挖掘
###1.什么是数据挖掘
Data Mining

* 又被称为**数据库中的知识发现**（KDD）  
机器学习和数据分析的理论及实践是数据挖掘研究的基础  
商业应用前景是数据挖掘研究工作的巨大推动力
* 传统的数据库查询和统计只能提供想要的信息，而数据挖掘技术可以发现没有意识到的未知信息
###2.具体定义
####定义一
对数据库中**蕴含的、未知的、非平凡的、有潜在应用价值的模式（规则）**的提取

* 非平凡的  
不能通过固定的计算方式得到
* 有潜在应用价值的  
虽然当前规则或模式是正确的，但这个模式在*目前技术条件*下无法用以改善生活、学习、生产，此规则也无效
* 模式  
可能以规则的方式进行表达
####定义二
从大型数据库的数据中提取人们**感兴趣的知识**，这些知识是**隐含的、事先未知的潜在有用信息**

* 感兴趣  
有用的
###3.数据挖掘的三个因素
* 数据挖掘的本源：大量、完整的数据
	* 如果数据量不大，当前的挖掘任务未必能得出正确结论
	* 如果不完整，结果可能无法放在更大样本上验证
* 数据挖掘的结果：知识、规则  
由于获取知识相当困难，我们希望得到知识候选，再以人的方式来筛选
* 结果的隐含性  
不是能够得到固定结果的计算  
因此需要挖掘的过程
###4.数据挖掘的特征
* 在大量的、完整的数据集中进行数据的挖掘工作
* 归纳结果应该是具有普遍性意义的规则  
在当前数据中得到的结论在更大规模的其它数据上有很大概率也成立
* 数据挖掘的目的：用归纳出的规律来指导客观世界
###5.数据挖掘的基本概念
####模式
* 任何用高级语言表达一定逻辑含义的信息都是模式  
携带信息，携带判断  
*无论对错都是模式*
* 通常指数据库中数据与数据之间的逻辑关系
####知识
满足用户对客观评价标准（兴趣度/置信度……）和主观评价标准要求的**模式**


* 只要与当前分析任务相匹配，客观指标可以任意制定
* *正是由于无法进行主观评价，机器转而提供一些客观标准，从而可以事先排除一些明显的错误*
#####置信度
在某一数据集上，模式成立的程度
> ######例：模式R1：在购买面包和黄油的顾客中，大部分的人同时也买了牛奶
> 该模式的置信度为：同时购买面包、黄油、牛奶的顾客人数占同时购买面包、黄油的顾客人数的百分比

* 置信度不是固定的
* 通过数据挖掘所发现的模式的置信度大小涉及到许多因素  
数据的完整性、样本数据的大小、领域知识的支持程度等
* 没有足够的置信度，模式便不能成为知识  
有意义的置信度要在良好的数据集中得到  
通常要规定模式的最小置信度，通过此阈值过滤掉一部分被认为并不正确的模式
#####兴趣度
在某一数据集上，模式被用户关注的程度
> ######例：R1同上
> 模式R1的支持度为同时购买面包，黄油和牛奶的顾客人数占总顾客人数的百分比

* 只有一个模式的兴趣度达到一定程度时，该模式才是有意义的模式  
才能引起用户的注意，有助于用户的决策制定过程  
因此数据挖掘过程中也要规定模式的最小兴趣度，以淘汰在极少情况下才会出现的模式
####非平凡性
#####平凡知识
能够以确定的计算过程提取的模式

*平凡的知识不是数据挖掘的目标*，因为这样的知识已经成为**常识**

在数据挖掘中，知识的发现过程都应具有某种*不确定性*和一定的*自由度*，即要发现不平凡的知识
####有效性
知识的发现过程必须能够有效地在计算机上实现

* 时间有效性
* 空间有效性

这限制了太复杂的相关算法是不能被应用于数据挖掘的  
*但往往可以应用于其它领域，如****人工智能***
###6.数据挖掘的特点
* 数据挖掘要处理大量的数据
* 由于用户不能形成精确的查询要求，因此要依靠数据挖掘技术为用户寻找他可能感兴趣的东西  
希望用户尽可能少的介入
* 在数据挖掘过程中，规则的发现基于统计规律  
发现的规则不必适用于所有数据
* 数据挖掘所发现的规则是动态的，只反映了当前状态的数据集合具有的规则  
数据挖掘以数据为导向，根据数据集的变化需要重新进行挖掘，以期望挖掘到新的规则  
*采用相同的算法，即使基于相同的数据也可能得到不同的结论*
###7.数据挖掘的相关领域
* 数据库系统  
数据源相关
* 统计学  
概率的讨论
* 机器学习  
算法的移植
* 信息科学  
定性、定量地计算需要的信息量，从而指导数据的挖掘
* 可视化  
挖掘过程的可视化、规则展现的可视化
* 其它学科  
多媒体、图像处理……

实际上数据挖掘是一门交叉型学科
##二、数据仓库与数据挖掘
###1.基于数据库和基于数据仓库的数据挖掘
* 数据挖掘建立在数据库的基础之上  
数据挖掘只是其中的一个部分，在此之前需要大量的数据查询和预处理
* 产生数据仓库技术后  
由于数据仓库中的数据都是经过抽取、整理和预处理后的综合数据，因而数据挖掘工作可以在数据仓库上直接运行  
任务相对来说会简单很多，*但并不代表数据挖掘可以无缝地架设在数据仓库之上*  
取决于数据仓库的数据结构与数据挖掘需要的数据结构之间的差距，不过这种转换只涉及到形式层面
###2.利用数据库系统进行数据挖掘的缺点
####动态数据
* 大多数数据库的基本特点是内容将经常变化  
* 在线系统中，必须采用预警机制来保证数据库中的这些变化不会导致错误的数据挖掘结果
####噪声和不确定性
* 噪声数据  
数据库中的错误数据和异常现象
* 不确定性  
发现的模式可能只在一部分数据上有效
####冗余信息
* 同一数据在操作型数据环境中的多处出现  
并不针对单个数据库，多个数据库拼合就可能发生此问题
* 有时会误导知识的发现过程
	* 可能会夸大某个模式的置信度
		> (A+B)/A**<**(A+B)+n/A+n
	* 可能会低估某个模式的兴趣度
		> (A+B)/A**>**(A+B)/A+n
####不完整数据
####稀疏数据
##三、数据挖掘的步骤
###1.数据挖掘技术在决策支持过程中的地位
见ppt第25页

* 问题域  
对当前需要回答的问题的大方向要有所了解
* 选择目标数据集  
哪些数据与当前的问题域相关  
数据仓库中包含大量分析型数据，而可能与当前问题没有直接关联  
增加处理、传输的开销，可能产生误导，处理能力也可能会有所限制  
采用人配合计算机以半自动的方式筛去部分数据
* 数据预处理  
转成当前数据挖掘所需要的样式
* ***数据挖掘***  
调用算法，得到模式的集合，精确地回答需要的问题
* 模式评价与理解  
可能会产生某些无法理解的结果或带来的误差  
如果满足不了用户的需要，向前回退到任意一个环节重新开始
* 决策支持应用  
交给实际与此模式相关的部门改进业务

数据挖掘是其中重要一环
###2.数据集成
* 数据挖掘的基础是数据，因此挖掘前必须进行数据集成
	* 从各类数据系统中提取挖掘所需的统一数据类型，建立一致的数据视图
	* 做数据加载，从而形成挖掘的数据挖掘的基础

目前一般用数据仓库实现数据集成
####通常需要做的预处理
#####数据清理
* 填补丢失的数据
* 清除噪声数据
* 修正数据的不一致性
#####数据集成
#####数据转换
我们收集到的数据有时并不一定适合数据挖掘的需要，如已有的挖掘方法可能无法处理这些数据，存在一些不规则的数据，或者数据本身不够充分等，因此需要对收集到的数据进行转换

*如果没有数据仓库，或者当前任务没有重复可能，可以建立一个小规模的数据集市，以期待后续能够自底向上地创建数据仓库*
###3.数据规约
* 用于数据挖掘的数据量非常巨大  
数据规约可以减低数据量，提高数据挖掘操作的性能  
如果在规约后的数据集上挖掘可以获得与原来一样或*几乎*一样的挖掘结果，就可以考虑采用一定的规约技术
####常见的数据规约技术
* 数据立方体计算
* 挖掘范围的选择  
	* 在不影响挖掘结果的前提下，尽可能地选取那些与挖掘操作有关的属性集  
	去除明显无关的因素，或由于法规、风俗等原因，即使有相应的分析结果也无法应用的
	* 时间范围或备份内容上的选择
* 数据压缩  
减低数据的规模，节省存储空间开销和数据通讯开销  
如果采用的数据挖掘算法不需要解压就可直接对压缩数据进行挖掘，数据压缩技术将非常有用
* 离散化处理  
将属性值的连续区域划分为若干个区域，用每个区域的标识代替原来的值，以减低该属性上属性值的个数  
也可利用这种数据规约技术来自动地建立该属性的概念层次树
###4.挖掘、评价
略
###5.表示
在计算机中用一定形式表现出来

* 可以包括文字、图形、表格、图标等可视化形式
* 也可同时用内部结构形式将结果写回数据仓库，供日后进一步分析
##四、常用的数据挖掘方法
目前常用的数据挖掘方法大多属于数学统计方法或人工智能中的机器学习算法，以及人工神经网络/遗传算法等
###1.特征规则挖掘
####特征规则
* 常见的知识形式，它用于描述一类数据对象的普遍特征，是普化知识的一种  
特征规则是基于概率的知识
* 特征规则的数据挖掘方法有**面向属性规约方法**和**数据立方方法**
####面向属性规约方法
* 常用的特征规则的挖掘方法  
通过对属性值间概念的层次结构进行规约，以获得相关数据的概括性知识
* 在实际情况中，许多属性都可以进行数据归类，形成概念汇聚点  
这些概念依抽象程度的不同可构成描述它们层次结构的**概念层次树**  
根据概念层次树可以对供挖掘用的数据进行预处理，以生成一个适合于进行数据挖掘工作的数据集  
*因此“面向属性”的数据规约过程实际上是为进行数据挖掘工作而进行的数据预处理*
#####概念层次树
某属性值所具有的从具体的概念值到概念类的层次关系树

* 一般由用户提供，或者从领域知识中得到相关属性的概念层次树
* 也可以通过多属性体系结构自动构建
#####规约
用概念层次树上高层的属性值去替代低层的属性值  
又称为**概念提升**
######规约的目的
* 规范化一个属性的取值
* 提高模式的置信度和兴趣度  
从而达到知识的阈值

*当前的规约面向的单位是一条元组中的一个属性，而OLAP中讨论的上钻和下钻是针对数据的汇总；实际上，如果良好地定义了OLAP中的某些聚集值，就可以用OLAP实现规约*
#####基本关系表
待挖掘的原始细节数据，以关系的形式出现，通常来自于准备好的数据库或数据仓库中
#####概括关系表
*如果通过规约，可以使当前的属性值数量在某一范围内，就如此实施规约；如果无法规约，就将这组属性去除；如果两组属性高度相关，就认为这两组属性冗余，去除其中一组*

将取值完全相同的元组进行合并，并附带一个COUNT属性，表示其规约了的基本元组数量  
*如果不需要节约存储空间，不进行合并也可以*
#####面向属性规约过程
见ppt
####数据立方方法
如果统计结果（主要是求和）已经预先计算出来存放在多维数据库中，就可以直接从多维数据库中获得所需要的统计结果，从而节省数据规约的时间，提高数据挖掘的效率
#####常用的分析方法
* 数据概括（roll_up，上翻）  
将属性值提升到较高的概念层次上
* 数据细化（roll_down，下翻）  
将属性值减低一些层次
#####特征规则挖掘与OLAP的区别
* 特征规则挖掘是由参数主导的**自动化**过程，而OLAP是由分析人员主导的**人工**过程
* 在特征规则挖掘过程中，算法可以在阈值的指导下：
	* 自动决定排除冗余以及和当前挖掘任务无关的属性
	* 自动决定各个属性规约的层次
	* 在对比集的指导下，在挖掘结果中取出与当前挖掘任务关联不大的属性
####概念描述：特征与区分
* 除了使用特征规则挖掘，发现目标集中蕴含的数据特点外，还可以在引入*对比集*后进行**区分规则挖掘**
* 特征规则挖掘和区分规则挖掘，是描述型数据挖掘的一体两面，共同构成对一个目标集的概念描述
###2.关联规则挖掘
####关联规则
* 关联规则用于表示事务数据库中诸多属性之间的关联程度
* 关联规则挖掘则是利用数据库中的大量数据通过关联算法寻找属性间的相关性
* 属性在这里被称为**项**  
若干个属性所构成的属性集被称为一个**项集**
	> ######例：超级市场
	> 在购买商品A的客户中有90%的人会同时购买商品B，则可用关联规则表示为：
	> 
	> 	R1：A->B
* A->B与B->A的兴趣度是相同的，但置信度通常不同
* 任意组合均构成关联规则  
为了发现有意义的关联规则，需要给定两个阈值：**最小兴趣度**和**最小置信度**
	* 满足最小置信度和最小兴趣度的规则为**强规则**，否则为**弱规则**
	* 关联规则挖掘的实质是*在数据库（数据仓库）中寻找强规则*
####Apriori算法
#####基本概念
* 项  
在数据库中出现的属性值，每一个属性值构成一个项
* 项集  
在数据库中出现的属性值的集合
* k-项集  
由k个项构成的项集
* 频繁项集  
该项集在数据库中出现的频度满足用户规定的最小支持度的要求  
即同时含有该项集中的所有属性值的记录数占所有记录数的百分比大于等于用户规定的最小支持度
* 关联规则一定是在满足用户的最小支持度要求的频繁项集中产生的  
关联规则的挖掘过程也就是在数据库中寻找频繁项集的过程  
寻找频繁项集过程中，遵循***每个频繁项集的任一子集也是一个频繁项集***
#####寻找频繁项集的方法
> * 寻找一阶频繁项集C1  
> 除去非频繁项集，得到L1
> * 从L1生成二阶超集，即候选频繁项集C2  
> 除去非频繁项集，得到L2
> * 从L2生成三阶超集C3  
> 除去暂时不需要考虑的更高阶超集  
> 除去非频繁项集，得到L3
> * ……
> 
> 最后得到的频繁项集是***L1、L2、L3……的并***

进行关联分析挖掘前，通常希望将数据库中的内容进行整合，这取决于数据集的定义，以及项集的形式
#####算法分析
* 得到的最大频繁项集长度与项的数量处在同一数量级
* 每求一次超集，就需要扫描一遍项集
#####生成关联规则
> * 针对频繁项集{A,C}可以构造两条规则
>  
> 		R1：A->C
> 		R2：C->A
> 一阶频繁项集无法构造关联规则，只能得到平凡知识  
> 将每个频繁项集分为左右两部分，穷举即可以得到
> * 对这些规则分别计算置信度  
> 计算置信度时不需要再扫描数据库
> * 通过预先设定的阈值对关联规则进行过滤
> * 针对生成的关联规则进行一些主观性的解读  
> 剔除已知的关联规则
> * 最后剩余的关联规则上升为知识，用于决策支持
#####Apriori算法的优化方法
由于算法是时间开销花在数据库的多次扫描上，主要的优化方法有：

* 数据库的划分（Partitioning）方法  
针对硬件限制进行优化  
虽然置信度和兴趣度指标可能有变化，但**所有关联规则一定都会出现在各个划分中**  
*划分可能导致产生的关联规则数量过大，提高阈值又会损失原有的规则*
	* 每一部分都能全部放在内存中进行扫描
	* 最后对得到的所有频繁项集进行归并
* 利用Hash方法筛选2阶频繁项集  
将每个项哈希到哈希表里，从而大量地过滤不需要的候选集
* 利用采样数据集得到可能成立的规则，再利用数据库中的剩余数据验证这些规则的正确性  
由于无法保证结论的正确性，此方式未必靠谱
* 减少每一遍扫描所处理的记录数

		如果一条记录不含有长度为k的频繁项集，那么这条记录也不可能含有长度为(k+1)的频繁项集
 
	得到所有k阶频繁项集后，以后的每次扫描就不必再访问上述的记录，从而逐步减少被扫描的记录数
####序列模式分析
序列模式分析与关联规则挖掘类似，也是为了找出数据对象之间的联系，但序列模式分析法的侧重点是为了找出数据对象之间的前后因果关系  
被分析的对象具有前后的**时序关系**
###3.分类分析
####数据分类
* 通过分析训练数据样本，产生关于类别的精确描述  
* 这种类别通常由分类规则组成，可以用来对未来的数据进行分类和预测

首先为每一个数据（记录）打上一个标记，即按标记对数据（记录）进行分类，而分类分析则是对每类数据（具有相同标记的一组记录）找出其固有的特征与规律。
####数据分类的步骤
#####建立一个模型，描述给定的数据类集或概念集，通过分析由属性描述的数据库元组来构造模型
* 用于建立模型的元组集称为训练数据集，其中每个元组成为训练样本  
训练样本的性质与待分析样本本质上没有差别，都是在实际环境中累积得到的数据
* 每个训练样本属于一个预定义的类，由类标号属性确定
* 由于给出了类标号属性，因此该步骤又成为有指导的学习  
需要知道分类的数量，与对应分类对人来说的意义  
*如果训练样本的类标号是未知的，则称为****无指导的学习（聚类）***
* 学习模型可以用分类规则、决策树和数学公式的形式给出
#####使用模型对数据进行分类
* 评估模型的分类准确性  
训练数据和测试数据性质应当是一样的，但不能是两份相同的数据  
评价的标准包括正确性、效率、可理解性
* 对类标号未知的元组按模型进行分类
####分类分析方法
是一种特征归纳的方法，将每类数据共有的特性抽取以获得规律性的规则，目前有很多分析方法

* 决策树方法
* 贝叶斯方法  
	* 通过前验概率和后验概率，决定某一特定样本属于标签中某一分类的概率  
	概率的值根据训练样本提供
	* 贝叶斯方法得到的结果不唯一，并且能提供相应结果的概率大小
	* 贝叶斯方法计算复杂  
	在各属性独立时，贝叶斯方法的计算可以简化

以上两种方法基于信息论，具有很好的**可剪枝性**

* 人工神经网络方法
	* 采用模拟生物神经元的方法进行分类
	* 每个神经元有多个输入，提供一个输出，包含多个参数，其中有矢量
	* 前一层神经元的输出作为下一层的输出
	* 将训练数据输入到神经元中，如果发生错误，通过对应的反馈机制进行调整
	* 通过若干次迭代完成调整
		* 结束条件
			* 正确率达到某个阈值
			* 调整的比例已经很小，模型达到稳定  
			正确率无法再有效提高
			* 在可以预见的未来中无法筛选出结果  
			此时，训练失败
	* 神经元网络的限制并不多，并不以属性为单位进行讨论  
	以元组为单位进行讨论
	* 一旦完成训练，分类将可以以硬件的方式进行，效率非常高  
	*不过形成对应的模型会非常慢*
* 约略集方法  
基于确定或不确定的边界进行的分类
* 遗传算法  
	* 将一般的属性和分类属性转化为一个**基因**（01串）  
	对应通过一个基本数据集对分类进行预测的规则
	* 最初通过随机的方式生成若干个基因
	* 根据成立的比例进行优胜劣汰
	* 效果最好的基因通过**遗传**和**变异**留下后代
	* 每次优胜劣汰称之为一次迭代，若干次迭代后就可得到最终的分类模型
#####决策树方法
又称为判定树，是运用于分类的一种树结构

* 根据对一个判定进行拆分，连接到下一个判定或结论，构成的关系就是一棵决策树
* 每个内部结点代表对某个属性的一次测试
* 每条边代表一个测试结果
* 叶结点代表某个类或者类的分布
* 最上面的结点是根结点
* 通过对信息量的计算，判断每个属性对分类所作判断的贡献大小  
将一个集合S拆分为S1和S2，其信息量大小有以下关系：

		I(S)≥I(S1)+I(S2)
		（在属性对分类不起任何作用时取等号）
		
		属性的信息增益A=I(S)-[I(S1)+I(S2)]

	将贡献最优的属性放在顶层，迭代进行
	* 中止条件
		* 训练数据集为空
		* 分类已经确定  
		I(S)=0
		* 属性已经用完，仍然无法确定地分类
* 由于有很好的理论支持，在*某种数据条件下*，决策树方法的效果非常好
###4.聚类分析
* 又称集群分析，它是研究分类问题的一种多元统计方法
* 分为**距离聚类**和**相似系数聚类**  
即定义相似程度的两种方式，不过实际上没必要严格地区分
* 没有筛选出一小部分数据，经过处理得到模型，再以此模型进行通用处理的两个阶段

####与分类分析的混合使用
由于聚类分析的时间复杂度与整体样本数量有关，因此可以抽样一部分数据进行聚类分析，得到结果后，对每个聚类进行概念规则挖掘，人为确定一些概念规则，再以此规则对剩余数据进行分类

* 聚类分析输入的是没有被标记的记录，系统按照一定的规则合理的划分记录集合  
相当于给记录打标记，但分类标准不是用户确定的
* 然后采用分类方法对数据进行分析，并根据分析结果重新对原来的记录集合进行划分，进而再进行一次分类分析  
如此循环往复，直到获得满意的分析结果
####主要的聚类方法
* 划分方法  
一些场景中，划分聚类的数量k是知道的；即使不知道划分聚类的数量，也是可以以穷举的方法进行确定的（1≤k≤N）
	* 随机地选择k个数据
	* 将其它所有数据打上距离最近的标记  
	完成一次迭代
	* 根据当前聚类选择一个实际（或虚拟）的数据点  
	具有代表性的
	* 第二次迭代，根据选择的点再进行一次划分  
	代表性的数据点继续发生变化
	* 如此循环往复，直到每个数据的聚类不再发生变化为止
	* 代表数据点的选择问题
		* 如果选择实际的数据点作为代表，选择的标准难以确定
		* 如果选择虚拟的数据点作为代表，数据点又可能没有意义  
		***需要根据实际任务选择类型***
* 层次的方法  
将相似程度最大的两个数据合并，以一个虚拟数据点作为其代表，重复进行计算
	* k值是可以不必给定的  
	以聚类内的相似程度和聚类间的相异程度作为指标
	* 没有迭代的过程，结果可能并不精确
* 基于密度的方法  
定义一个**密度连通**的概念与阈值k、R

	> * 对一个数据点A，只有在其半径R范围内存在至少k个点，这个数据才是具有代表性的；如果B落在这个范围内，那么A到B是**直接可达**的  
	> *密度连通不是可逆关系*
	> * 如果A与B直接可达，B与C直接可达，那么A与C**间接可达**
	> * 如果A与M密度可达，A与N密度可达，那么M与N**密度连通**
	> * 所有密度连通的数据落在同一个聚类中
	* 避免了划分与层次中凸多边形的问题
	* 通过调整k和R可以控制聚类数量
* 基于网络的方法  
通过数量可变/不可变的，静态/动态的网格，以整个格子作为整体进行分析
	* 难免会产生马赛克现象
	* 格子的大小不好确认
* 基于模型的方法  
基于概率论的方式进行分类，与决策树的方式相关
* *回归与预测的方法*  
根据当前数据的坐标，预测一个连续、未知的数值的取值  
通常不认为是数据挖掘的内容，而属于数理统计范畴
##五、数据挖掘的应用
###1.金融业
* 对账户进行信用等级评估  
分类、聚类为主的数据挖掘方法
* 股票交易规律分析  
关联与时序
* 信用卡使用模式分析  
明确的聚类方法，会带来很多有益的信息  
可以定期进行非优质客户行为的筛选
* 金融市场的分析和预测
###2.保险业
* 保险费率的确定  
可以从大量客户投保数据中分析并取得不同条件、不同人员、不同险种、不同时间与年龄的保险费率，使保险业主能获得合理的利润
* 险种关联分析  
可以分析客户在购买了某种保险后是否同时还会购买另一种保险
* 认购险种的预测  
可以通过数据挖掘预测新险种的客户群以及新险种的前景
###3.零售业
* 分析顾客行为与习惯
* 分析商场销售商品的构成
* 用于商品销售预测、商品价格分析以及零售点设置布局等方面
###4.科学研究
数据挖掘可以从大量的、漫无边际的实验数据与历史资料中提炼出对科学规则发现有用的信息，从而起到协助科学规律发现的作用
###5.其它行业
* 医疗
* 电信
* 司法
* 故障诊断
* ……
###6.应用实例
> 见ppt

从中发现的关联规则与特征规则、分类知识可以指导今后的业务运作
###6.复杂类型数据源的数据挖掘
数据挖掘可以运行在非结构化的数据环境上
####Web数据挖掘
* Web内容挖掘
* Web结构挖掘
* Web使用记录挖掘
####空间数据库挖掘
空间数据库存储了大量与空间有关的矢量数据，如地图、遥感或医学图像数据

* 没有数据挖掘前，这些数据由人工进行分析
* 医学数据可能无法自动化处理，但至少可以用于进行预处理，减少人的工作量
####多媒体数据库挖掘
* 对图像、音频、视频的检索
* 与模式识别有关
####时间序列数据挖掘
* 一些时间序列数据可能是实时的  
需要根据实时数据，**准实时地**提供某些建议
* 计算量和数据量间需要进行平衡